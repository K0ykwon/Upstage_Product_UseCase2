import streamlit as st
from utils.pdf_upload import process_document
from utils.request_rag import call_rag_api
from utils.openai_chat import (
    summarize_document, 
    answer_question_with_memory, 
    document_based_qa_with_memory, 
    stream_chat_response_with_memory
)
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI Document Assistant",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë¨¼ì € ì‹¤í–‰)
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processed_pdf" not in st.session_state:
    st.session_state.processed_pdf = None
if "pdf_summary" not in st.session_state:
    st.session_state.pdf_summary = None

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ğŸ“„ Document Assistant")
    st.markdown("---")
    
    # PDF ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ", 
        type=["pdf"],
        help="ë¶„ì„í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    force_ocr = st.checkbox(
        "ê°•ì œ OCR ì‚¬ìš©", 
        value=False,
        help="ì´ë¯¸ì§€ ê¸°ë°˜ PDFì˜ ê²½ìš° ì²´í¬í•˜ì„¸ìš”"
    )
    
    # ìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜ ì¶”ê°€
    use_streaming = st.checkbox(
        "ì‹¤ì‹œê°„ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)", 
        value=True,
        help="ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì•„ë³´ê¸°"
    )
    
    if uploaded_file:
        st.success(f"âœ… {uploaded_file.name} ì—…ë¡œë“œë¨")
    
    st.markdown("---")
    st.markdown("### ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. **PDF ì—…ë¡œë“œ í›„ ìš”ì²­**: PDF ì—…ë¡œë“œ â†’ "ë¬¸ì„œ ìš”ì•½í•´ì¤˜" ì…ë ¥
    2. **í…ìŠ¤íŠ¸ë§Œ ì…ë ¥**: ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì œê³µ
    3. **PDF + êµ¬ì²´ì  ì§ˆë¬¸**: ë¬¸ì„œ ê¸°ë°˜ ë§ì¶¤ ë‹µë³€
    
    ğŸ’¡ **íŒ**: PDF ì—…ë¡œë“œ í›„ ì›í•˜ëŠ” ìš”ì²­ì‚¬í•­ì„ í•¨ê»˜ ì…ë ¥í•˜ì„¸ìš”!
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ¤– AI ëª¨ë¸")
    st.info("**Upstage Solar Pro2 Preview**\n- OpenAI í˜¸í™˜ API ì‚¬ìš©\n- ê³ ì„±ëŠ¥ ì¶”ë¡  ì—”ì§„\n- ğŸ§  ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬")
    
    # ë©”ëª¨ë¦¬ ìƒíƒœ í‘œì‹œ
    if len(st.session_state.messages) > 14:  # 7ê°œ ëŒ€í™” = 14ê°œ ë©”ì‹œì§€
        st.warning(f"ğŸ’¾ **ë©”ëª¨ë¦¬ ê´€ë¦¬ í™œì„±í™”**\n- ìµœê·¼ 7ê°œ ëŒ€í™”: ì „ì²´ ë³´ê´€\n- ì´ì „ ëŒ€í™”: ìš”ì•½ ì €ì¥\n- ì´ {len(st.session_state.messages)//2}ê°œ ëŒ€í™”")
    else:
        st.success(f"ğŸ’¾ **ì „ì²´ ëŒ€í™” ë³´ê´€ ì¤‘**\n- í˜„ì¬ {len(st.session_state.messages)//2}ê°œ ëŒ€í™”\n- 8ê°œì§¸ë¶€í„° ìš”ì•½ ì €ì¥")

# ë©”ì¸ í™”ë©´
st.title("ğŸ¤– AI Document Assistant")
st.markdown("PDF ë¬¸ì„œ ë¶„ì„ê³¼ ì§ˆë¬¸ ë‹µë³€ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (PDFë§Œ ì—…ë¡œë“œí•œ ê²½ìš° 'ë¬¸ì„œ ìš”ì•½í•´ì¤˜' ë“±ì„ ì…ë ¥í•˜ì„¸ìš”)")

# ë©”ì‹œì§€ ì²˜ë¦¬ - ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í–ˆì„ ë•Œë§Œ ì‹¤í–‰
if user_input:
    # ì¼€ì´ìŠ¤ íŒë‹¨
    has_pdf = uploaded_file is not None
    has_text = user_input is not None and user_input.strip() != ""
    
    if has_pdf and has_text and any(keyword in user_input.lower() for keyword in ['ìš”ì•½', 'ë¶„ì„', 'ì •ë¦¬', 'ì„¤ëª…', 'ë‚´ìš©']):
        # ì¼€ì´ìŠ¤ 1: PDF ì—…ë¡œë“œ + ë¬¸ì„œ ê´€ë ¨ ìš”ì²­
        with st.chat_message("user"):
            st.markdown(f"ğŸ“„ **ë¬¸ì„œ:** {uploaded_file.name}\n\nğŸ’¬ **ìš”ì²­:** {user_input}")
        
        st.session_state.messages.append({
            "role": "user", 
            "content": f"ğŸ“„ **ë¬¸ì„œ:** {uploaded_file.name}\n\nğŸ’¬ **ìš”ì²­:** {user_input}"
        })
        
        with st.chat_message("assistant"):
            with st.spinner("PDFë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ì¤‘..."):
                try:
                    # PDF ì²˜ë¦¬
                    file_bytes = uploaded_file.read()
                    plain_text, error = process_document(file_bytes, force_ocr)
                    
                    if error:
                        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}")
                    elif plain_text:
                        # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ë¬¸ì„œ ì²˜ë¦¬
                        st.session_state.processed_pdf = plain_text
                        response = ""
                        
                        if 'ìš”ì•½' in user_input.lower():
                            summary = summarize_document(plain_text)
                            if summary:
                                st.session_state.pdf_summary = summary
                                response = f"""
## ğŸ“‹ ë¬¸ì„œ ìš”ì•½

{summary}

---

### ğŸ” ìœ ì‚¬ ë³´ê³ ì„œ ê²€ìƒ‰ ì¤‘...
"""
                        else:
                            # ê¸°íƒ€ ìš”ì²­ (ë¶„ì„, ì •ë¦¬, ì„¤ëª… ë“±)
                            doc_response = document_based_qa_with_memory(
                                plain_text[:2000],  # ë¬¸ì„œ ì¼ë¶€ë§Œ ì‚¬ìš©
                                user_input,
                                st.session_state.messages[:-1]  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
                            )
                            
                            if doc_response:
                                response = f"""
## ğŸ“‹ {user_input}

{doc_response}

---

### ğŸ” ìœ ì‚¬ ë³´ê³ ì„œ ê²€ìƒ‰ ì¤‘...
"""
                            else:
                                # ê¸°ë³¸ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
                                summary = summarize_document(plain_text)
                                if summary:
                                    st.session_state.pdf_summary = summary
                                    response = f"""
## ğŸ“‹ ë¬¸ì„œ ìš”ì•½

{summary}

---

### ğŸ” ìœ ì‚¬ ë³´ê³ ì„œ ê²€ìƒ‰ ì¤‘...
"""
                        
                        if response:
                            # RAG API í˜¸ì¶œë¡œ ìœ ì‚¬ ë³´ê³ ì„œ ê²€ìƒ‰
                            try:
                                search_query = st.session_state.pdf_summary if st.session_state.pdf_summary else user_input
                                rag_response = call_rag_api(f"ìœ ì‚¬í•œ ë³´ê³ ì„œë‚˜ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”: {search_query}")
                                
                                if rag_response and "results" in rag_response:
                                    similar_docs = "### ğŸ“š ìœ ì‚¬ ë³´ê³ ì„œ/ë¬¸ì„œ\n\n"
                                    for i, result in enumerate(rag_response["results"][:3], 1):
                                        similar_docs += f"**{i}. {result.get('title', 'ì œëª© ì—†ìŒ')}**\n"
                                        similar_docs += f"{result.get('content', 'ë‚´ìš© ì—†ìŒ')[:200]}...\n\n"
                                    
                                    st.markdown(similar_docs)
                                    response += similar_docs
                                else:
                                    fallback = "### ğŸ“š ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                                    st.markdown(fallback)
                                    response += fallback
                                    
                            except Exception as e:
                                error_msg = f"### âš ï¸ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
                                st.markdown(error_msg)
                                response += error_msg
                            
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": response
                            })
                        else:
                            error_msg = "ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            st.error(error_msg)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": f"âŒ {error_msg}"
                            })
                    else:
                        error_msg = "PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        st.error(error_msg)
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": f"âŒ {error_msg}"
                        })
                        
                except Exception as e:
                    error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": f"âŒ {error_msg}"
                    })
    
    elif not has_pdf and has_text:
        # ì¼€ì´ìŠ¤ 2: í…ìŠ¤íŠ¸ë§Œ ì…ë ¥
        with st.chat_message("user"):
            st.markdown(user_input)
        
        st.session_state.messages.append({
            "role": "user", 
            "content": user_input
        })
        
        with st.chat_message("assistant"):
            try:
                if use_streaming:
                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ë©”ëª¨ë¦¬ í¬í•¨)
                    system_prompt = """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
ëŒ€í™”ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³  ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
ëª¨ë¥´ëŠ” ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    for chunk in stream_chat_response_with_memory(st.session_state.messages, system_prompt, user_input):
                        full_response += chunk
                        response_placeholder.markdown(full_response + "â–Œ")
                    
                    response_placeholder.markdown(full_response)
                    
                    # RAG APIë¡œ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰
                    try:
                        with st.spinner("ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                            rag_response = call_rag_api(user_input)
                            
                            if rag_response and "results" in rag_response and rag_response["results"]:
                                additional_info = "\n\n### ğŸ“š ì°¸ê³  ìë£Œ:\n"
                                for i, result in enumerate(rag_response["results"][:2], 1):
                                    additional_info += f"**{i}.** {result.get('content', 'ë‚´ìš© ì—†ìŒ')[:150]}...\n\n"
                                
                                full_response += additional_info
                                response_placeholder.markdown(full_response)
                    except:
                        pass  # RAG ê²€ìƒ‰ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ë‹µë³€ì€ ìœ ì§€
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": full_response
                    })
                else:
                    # ì¼ë°˜ ì‘ë‹µ (ë©”ëª¨ë¦¬ í¬í•¨)
                    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        response = answer_question_with_memory(user_input, st.session_state.messages)
                        
                        if response:
                            # RAG APIë¡œ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰
                            try:
                                rag_response = call_rag_api(user_input)
                                
                                if rag_response and "results" in rag_response and rag_response["results"]:
                                    response += "\n\n### ğŸ“š ì°¸ê³  ìë£Œ:\n"
                                    for i, result in enumerate(rag_response["results"][:2], 1):
                                        response += f"**{i}.** {result.get('content', 'ë‚´ìš© ì—†ìŒ')[:150]}...\n\n"
                            except:
                                pass  # RAG ê²€ìƒ‰ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ë‹µë³€ì€ ìœ ì§€
                            
                            st.markdown(response)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": response
                            })
                        else:
                            error_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                            st.error(error_msg)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": f"âŒ {error_msg}"
                            })
                    
            except Exception as e:
                error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": f"âŒ {error_msg}"
                })
    
    elif has_pdf and has_text:
        # ì¼€ì´ìŠ¤ 3: PDF + êµ¬ì²´ì  ì§ˆë¬¸
        with st.chat_message("user"):
            st.markdown(f"ğŸ“„ **ë¬¸ì„œ:** {uploaded_file.name}\n\nğŸ’¬ **ì§ˆë¬¸:** {user_input}")
        
        st.session_state.messages.append({
            "role": "user", 
            "content": f"ğŸ“„ **ë¬¸ì„œ:** {uploaded_file.name}\n\nğŸ’¬ **ì§ˆë¬¸:** {user_input}"
        })
        
        with st.chat_message("assistant"):
            try:
                # PDF ì²˜ë¦¬ (ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê²½ìš°)
                if st.session_state.processed_pdf is None:
                    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                        file_bytes = uploaded_file.read()
                        plain_text, error = process_document(file_bytes, force_ocr)
                        
                        if error:
                            st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}")
                            st.stop()
                        
                        if plain_text:
                            summary = summarize_document(plain_text)
                            st.session_state.processed_pdf = plain_text
                            st.session_state.pdf_summary = summary
                
                # ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€
                if use_streaming:
                    # ìŠ¤íŠ¸ë¦¬ë° ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ (ë©”ëª¨ë¦¬ í¬í•¨)
                    system_prompt = f"""ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ë‹µë³€
[êµ¬ì²´ì ì¸ ë‹µë³€ ë‚´ìš©]

## ê·¼ê±°
[ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¶€ë¶„]

## ì¶”ê°€ ì •ë³´
[ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë‚˜ ì œì•ˆì‚¬í•­]

ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•´ì£¼ì„¸ìš”.

ì°¸ì¡° ë¬¸ì„œ ìš”ì•½:
{st.session_state.pdf_summary or st.session_state.processed_pdf[:1000]}"""
                    
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    for chunk in stream_chat_response_with_memory(st.session_state.messages, system_prompt, user_input):
                        full_response += chunk
                        response_placeholder.markdown(full_response + "â–Œ")
                    
                    # ë¬¸ì„œ ì •ë³´ ì¶”ê°€
                    doc_info = f"""

---

### ğŸ“„ ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´
- **íŒŒì¼ëª…:** {uploaded_file.name}
- **ë¶„ì„ ì™„ë£Œ:** âœ…
"""
                    full_response += doc_info
                    response_placeholder.markdown(full_response)
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": full_response
                    })
                else:
                    # ì¼ë°˜ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ (ë©”ëª¨ë¦¬ í¬í•¨)
                    with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë§ì¶¤ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        response = document_based_qa_with_memory(
                            st.session_state.pdf_summary or st.session_state.processed_pdf[:1000], 
                            user_input,
                            st.session_state.messages
                        )
                        
                        if response:
                            response += f"""

---

### ğŸ“„ ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´
- **íŒŒì¼ëª…:** {uploaded_file.name}
- **ë¶„ì„ ì™„ë£Œ:** âœ…
"""
                            
                            # RAG APIë¡œ ì¶”ê°€ ì°¸ê³  ìë£Œ ê²€ìƒ‰
                            try:
                                rag_response = call_rag_api(f"ë¬¸ì„œ: {st.session_state.pdf_summary} ì§ˆë¬¸: {user_input}")
                                
                                if rag_response and "results" in rag_response and rag_response["results"]:
                                    response += "\n### ğŸ“š ì¶”ê°€ ì°¸ê³  ìë£Œ:\n"
                                    for i, result in enumerate(rag_response["results"][:2], 1):
                                        response += f"**{i}.** {result.get('content', 'ë‚´ìš© ì—†ìŒ')[:150]}...\n\n"
                            except:
                                pass
                            
                            st.markdown(response)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": response
                            })
                        else:
                            error_msg = "ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            st.error(error_msg)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": f"âŒ {error_msg}"
                            })
                    
            except Exception as e:
                error_msg = f"ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": f"âŒ {error_msg}"
                })

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ"):
        st.session_state.messages = []
        st.session_state.processed_pdf = None
        st.session_state.pdf_summary = None
        st.rerun()

with col2:
    st.markdown("**í˜„ì¬ ìƒíƒœ:**")
    if st.session_state.processed_pdf:
        st.success("ğŸ“„ ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ")
    else:
        st.info("ğŸ“„ ë¬¸ì„œ ëŒ€ê¸° ì¤‘")

with col3:
    st.markdown(f"**ëŒ€í™” ìˆ˜:** {len(st.session_state.messages)//2}")

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em;'>
    ğŸ¤– Powered by Upstage Solar Pro2 Preview | OpenAI Compatible API
    </div>
    """, 
    unsafe_allow_html=True
)

