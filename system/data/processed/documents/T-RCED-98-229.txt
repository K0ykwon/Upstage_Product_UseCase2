GAO For Release on Delivery Expected at 2:30 p.m. EDT Wednesday June 17, 1998 United States General Accounting Office Testimony Before the Subcommittee on Financial Institutions and Consumer Credit, Committee on Banking and Financial Services, House of Representatives COMMUNITY DEVELOPMENT Early Results of the Community Development Financial Institutions Fund's Programs Statement of Judy A. England-Joseph, Director, Housing and Community Development Issues, Resources, Community, and Economic Development Division Madam Chair and Members of the Committee: We are pleased to be here today to discuss the preliminary results of our ongoing review of the administration of the Community Development Financial Institutions (CDFI) Fund. As you know, access to credit and investment capital is essential for creating and retaining jobs, developing affordable housing, revitalizing neighborhoods, and promoting the development and growth of small businesses. Community-based financial institutions have improved the economic well-being of economically distressed communities and their residents through lending and investments tailored to these communities. In 1994, recognizing that such community-based institutions were relatively few in number and small in size and often had difficulty meeting the demand for their services, the Congress created the CDFI Fund.1 To date, the Fund has sought to expand access to credit and other financial services in distressed communities primarily through two programs-the CDFI and the Bank Enterprise Award (BEA) programs. The CDFI program provides financial and technical assistance to a wide range of for-profit and nonprofit financial institutions to support their activities in distressed communities and monitors their performance over a period of at least 5 years.2 The BEA program rewards banks for increased lending and investments in CDFIS or in distressed communities. To receive their awards, banks must prove that they have made eligible loans or investments, but the Fund has no long-term monitoring role in this program. Our testimony today focuses on the first year's performance of the CDFI and BEA programs and identifies opportunities for improving their effectiveness. Because participants in the CDFI program are just beginning to report preliminary results, our discussion of this program will focus on the Fund's progress in developing performance measures for awardees and systems to monitor and evaluate their progress. In contrast, participants in the BEA program have largely completed the activities for which they are rewarded; therefore, we will discuss the impact of the program on banks' investments in CDFIS and distressed communities. Finally, our testimony will review the Fund's progress in meeting the strategic planning requirements of the Government Performance and Results Act of 1993 (Results Act). 1Riegle Community Development and Regulatory Improvement Act of 1994 (P.L.103-325, Sept. 23, 1994). 2The principal types of institutions the CDFI program supports are community development banks and bank holding companies, community development credit unions, business loan funds, housing loan funds, and community development venture capital funds. Our testimony is based on the experience of the institutions that received fiscal year 1996 awards. In the CDFI program, the Fund selected 31 of 268 applicants, largely on the basis of the business plans in which they laid out their proposals for economic revitalization and community development. In the BEA program, over 50 banks applied for awards and the Fund chose 38, basing its selection on the increased investments in CDFIS and distressed communities that the banks projected. The Fund reserved about $37 million for awardees in the CDFI program and $13.1 million for banks selected to participate in the BEA program. To obtain in-depth information about the two programs, we visited six CDFIS and five participating banks. In summary, our preliminary analysis shows the following: As of January 1998, the Fund had entered into assistance agreements with 26 of the 31 CDFIS that received awards in 1996. These agreements include performance goals and measures that were based on the business plans submitted by awardees in their application packages and negotiated between the Fund and the awardees, as the CDFI Act requires. These agreements are consistent with the program's objectives. Because the CDFI Act provides no specific guidance for evaluating performance measures, we used Results Act guidance. We found that the performance measures in the assistance agreements generally assess activities (such as the number of loans made) rather than accomplishments reflecting the results of activities (such as the number of new low-income homeowners). According to Fund officials and CDFIS in our case studies, this emphasis on activity measures is due, in part, to difficulties in isolating and assessing the results of community development initiatives, which may not be observable for many years and may be subject to factors outside the awardees' control. We further found that although the performance measures in the assistance agreements are generally related to specific goals, they do not always address all key aspects of the goals, and most assistance agreements lack baseline data that would facilitate tracking progress over time. The Fund has developed reporting requirements for awardees to collect information for monitoring their performance and is developing postaward monitoring procedures for assessing their compliance with their assistance agreements. The Fund currently does not have a system for evaluating the impact of awardees' activities. Although the Fund has disbursed about 80 percent of the fiscal year 1996 BEA award funds, it is difficult to determine the extent to which the program has encouraged the 38 awardees to increase their investments in distressed communities. Our case studies of five awardees and interviews with Fund officials indicate that although the prospect of receiving a BEA award prompted some banks to increase their investments, regulatory or economic incentives motivated other banks. In addition, some banks do not collect all of the data on their activities needed to guarantee that increases in investments under the BEA program are not being offset by decreases in other investments in these distressed areas. Furthermore, the Fund cannot be assured that banks' increased investments remain in place because it does not require banks to report any material changes in the status of these investments. Although banks have statutory discretion to use their BEA awards as they choose, most have told the Fund that they are furthering the BEA program's objectives by investing a portion or all of their awards in loans or investments supporting community development. The CDFI Fund's strategic plan contains all of the elements required by the Results Act and OMB'S associated guidance, but these elements generally lack the clarity, specificity, and linkage with one another that the act envisioned. Although the plan identifies key external factors that could affect the Fund's mission, it does not relate these factors to the Fund's strategic goals and objectives and does not indicate how the Fund will take the factors into account when assessing awardees' progress toward goals. In addition, the plan does not describe the relationship of its activities to similar activities in other government agencies, and it does not indicate whether or how the Fund coordinated with other agencies in developing its strategic plan. These shortcomings are similar to those in other federal agencies' initial efforts to comply with the Results Act and OMB'S associated guidance. Background Currently located within the Department of the Treasury, the CDFI Fund was authorized in 1994 and has received appropriations totaling $225 million through fiscal year 1998. The 1995 Rescissions Act limited the Fund to 10 full-time-equivalent staff for fiscal years 1995 and 1996, but for fiscal year 1998, the Fund has a ceiling of 35 full-time staff. As of May 1998, the Fund had 27 full-time and 2 part-time staff. The Fund's overall performance is subject to the general guidance set forth in the Community Development Banking and Financial Institutions Act of 1994 (CDFI Act), 3 which established the Fund. In addition, the Fund's overall performance is subject to the Results Act and the Office of Management and Budget's (OMB) implementing guidance. The latter act 3This legislation is title I of the Riegle Community Development and Regulatory Improvement Act of 1994. seeks to improve the management of federal programs and their effectiveness and efficiency by establishing a system for agencies to set goals for performance and measure the results. Under the act, federal agencies must develop a strategic plan that covers a period of at least 5 years and includes a mission statement, long-term general goals, and strategies for reaching those goals. Agencies must report annually on the extent to which they are meeting their annual performance goals and identify the actions needed to reach or modify the goals they have not met. The Fund completed its final plan in September 1997 and is currently considering revisions to that plan. Stronger Performance Measures Would Provide a Better Basis for Monitoring and Evaluating the CDFI Program's Accomplishments While the assistance agreements that the Fund negotiated with awardees in the CDFI program satisfy the CDFI Act's requirements for performance measurement, they include more measures of activity (what the awardees will do) than of accomplishment (how the awardees' activities will affect distressed communities) and do not always include measures for key aspects of goals. In addition, baseline information that was available to the Fund seldom appears in the Fund's performance measurement schedule. A more comprehensive performance measurement system would provide better indicators for monitoring and evaluating the program's results. Progress in Developing Performance Measures Is Mixed The CDFI Fund's progress in developing performance goals and measures for awardees in the CDFI program is mixed. On the one hand, the Fund has entered into assistance agreements with most of the 1996 awardees. As the CDFI Act requires, these assistance agreements include performance measures that (1) the Fund negotiated with the awardees and (2) are generally based on the awardees' business plans. On the other hand, the Fund's performance goals and measures fall somewhat short of the standards for performance measures established in the Results Act. Although awardees' assistance agreements are not subject to the Results Act, the act establishes performance measurement standards for the federal government, including the CDFI Fund. In the absence of specific guidance on performance measures in the CDFI Act, we drew on Results Act guidance for discussion purposes.4 4The Results Act, supplemented by Circular A-11, the Office of Management and Budget's (OMB) implementing guidance, and the GAO document entitled The Results Act: An Evaluator's Guide to Assessing Agency Annual Performance Plans (GAO/GGD-10.1.20, April 1998) provides more explicit guidance for developing performance goals and measures than the CDFI legislation. These three documents combined account for the Results Act guidance referred to in the balance of this statement. The assistance agreements called for under the CDFI Act require awardees to comply with multiple provisions, including the accomplishment of agreed-upon levels of performance by the final evaluation date, typically 5 years in the future. As of January 1998, the Fund had entered into assistance agreements with 26 of the 31 awardees for 1996. We found, on the basis of our six case studies, that the Fund had negotiated performance goals that met the statutory requirements and established goals for awardees that match the Fund's intended purpose, extensively involved the awardees in crafting their planned performance, and produced a flexible schedule for designing goals and measures. According to Results Act guidance, both activity measures, such as the number of loans made, and accomplishment measures, such as the number of new low-income homeowners, are useful measures. However, the act regards accomplishment measures as more effective indicators of a program's results because such measures identify the outcome of the activities performed. Our survey of CDFIS nationwide, including the 1996 awardees, and our review of six case study awardees' business plans showed that CDFIS use both types of measures to assess their progress toward meeting their goals. Yet our review of the 1996 awardees' assistance agreements revealed a far greater use of activity measures. As a result, the assistance agreements focus primarily on what the awardees will do, rather than on how their activities will affect the distressed communities. According to most of the case study awardees, their use of accomplishment measures was limited by concerns about isolating and measuring the results of community development efforts, as well as concerns about the Fund's possible imposition of sanctions for not meeting performance benchmarks subject to factors outside their control. According to Results Act guidance, goals and measures should be clear. We found that the goals and measures had varying degrees of clarity. For instance, most goals and measures were related; however, in some agreements, the measures did not address all key aspects of the goals. Finally, under Results Act guidance, clarity in performance measurement is also best achieved through the use of specific units, well-defined terms, and baseline and target values and dates. While the measures in the agreements included most of these elements, they generally lacked baseline values and dates. Fund officials told us that they used baseline values and dates in negotiating the performance measures, but this information did not appear in the assistance agreements themselves. Therefore, without information contained in awardees' files, it is difficult to determine the level of increase or contribution the investment is intended to achieve. Refining the awardees' goals and measures to meet Results Act guidance will facilitate the Fund's assessment of the awardees' progress over time. The Fund is taking steps to avoid some of the initial shortcomings in future agreements and is seeking to enhance its expertise and staffing. Mandated Monitoring and Evaluation Systems Are Not Yet in Place Although the Fund has developed reporting requirements for awardees to collect information for monitoring their performance, it lacks documented postaward monitoring procedures for assessing their compliance with their assistance agreements, determining the need for corrective actions, and verifying the accuracy of the information collected. In addition, the Fund has not yet established procedures for evaluating the impact of awardees' activities. The effectiveness of the Fund's monitoring and evaluation systems will depend, in large part, on the quality of the information being collected through the required reports and the Fund's assessment of awardees' compliance and the impact of awardees' activities. Primarily because of statutorily imposed staffing restrictions in fiscal years 1995 and 1996 and subsequent departmental hiring restrictions, the Fund has had a limited number of staff to develop and implement its monitoring and evaluation systems. In fiscal year 1998, it began to hire management and professional staff to develop monitoring and evaluation policies and procedures. The Fund has established quarterly and annual reporting requirements for awardees in their assistance agreements. Each awardee is to describe its progress toward its performance goals, demonstrate its financial soundness, and maintain appropriate financial information. However, according to an independent audit recently completed by KPMG Peat Marwick, the Fund lacks formal, documented postaward monitoring procedures to guide Fund staff in their oversight of awardees' activities. In addition, Fund officials indicated that they had not yet established a system to verify information submitted by awardees through the reporting processes. Fund staff told us that they had not developed postaward monitoring procedures because of the CDFI program's initial staffing limits. Now that additional staff are in place, they have begun to focus their attention on monitoring issues, including those identified by KPMG Peat Marwick. Preliminary Reports Describe Early Postaward Activity The CDFI statute also specifies that the Fund is to annually evaluate and report on the activities carried out by the Fund and the awardees. According to the Conference Report for the statute, the annual reports are to analyze the leveraging of private assistance with federal funds and determine the impact of spending resources on the program's investment areas, targeted populations, and qualified distressed communities. To date, the Fund has published two annual reports, the second of which contains an estimate of the private funding leveraged by the CDFI funding. This estimate is based on discussions with CDFIS and CDFI trade association representatives, not on financial data collected from the awardees. In part because it has been only 16 months since the Fund made its first investment in a CDFI, information on performance in the CDFI program is not yet available for a comprehensive evaluation of the program's impact, such as the Conference Report envisions. The two annual reports include anecdotes about individuals served by awardees and general descriptions of awardees' financial services and initiatives, but they do not evaluate the impact of the program on its investment areas, targeted populations, and qualified distressed communities. Satisfying this requirement will entail substantial research and analysis, as well as expertise in evaluation and time for the program's results to unfold. Fund officials have acknowledged that their evaluation efforts must be enhanced, and they have planned or taken actions toward improvement. For instance, the Fund has developed preliminary program evaluation options, begun hiring staff to conduct or supervise the research and evaluations, and revised the assistance agreements for the 1997 awardees to require that they annually submit a report to assist the Fund in evaluating the program's impact. However, because the Fund has not yet finished hiring its research and evaluation staff, it has not yet reached a final decision on what information it will require from the awardees to evaluate the program's impact. The Fund also has to determine how it will integrate the results of awardees' reported performance measurement or recent findings from related research into its evaluation plans. As to be expected, reports of accomplishments in the CDFI program are limited and preliminary. Because most CDFIS signed their assistance agreements from March 1997 through October 1997, the Fund has just begun to receive the required quarterly reports, and neither the Fund nor we have verified the information in them. Through February 1998, the Fund had received 41 quarterly reports from 19 CDFIS, including community development banks, community development credit unions, nonprofit loan funds, microenterprise loan funds, and community development venture capital funds. The different types of CDFIS support a variety of activities, whose results will be measured against different types of performance measures. Given the variety of performance measures for the different types of CDFIS, it is difficult to summarize the performance reported by the 19 CDFIS. To illustrate cumulative activity in the program to date, we compiled the data reported for the two most common measures-the total number of loans for both general and specific purposes and the total dollar value of these loans. According to these data, the 19 CDFIS made over 1,300 loans totaling about $52 million. In addition, the CDFIS reported providing consumer counseling and technical training to 480 individuals or businesses. Impact of BEA Awards on Banks' Investment Activities Is Difficult to Assess In the BEA program, as of January 1998, about 58 percent of the banks had completed the activities for which they received the awards and the Fund had disbursed almost 80 percent of the $13.1 million awarded in fiscal year 1996. Despite this level of activity, the impact of the program on banks' investments in distressed communities is difficult to assess. Our case studies of five awardees and interviews with Fund officials indicate that although the BEA awards encouraged some banks to increase their investments, other regulatory or economic incentives were equally or more important for other banks. In addition, more complete data on some banks' investments are needed to guarantee that the increases in investments in distressed areas rewarded by the BEA program are not being offset by decreases in other investments in these distressed areas. Furthermore, the Fund cannot be assured that the banks' increased investments remain in place because it does not require banks to report any material changes in these investments. Although the CDFI statute does not require awardees to reinvest their awards in community development, most banks that got BEA awards in 1996 have told the Fund that they have done so, thereby furthering the BEA program's objectives, according to the Fund. Regulatory and Economic Incentives Also Motivate Increased Investment in CDFIs and Distressed Areas Our analysis indicated that the impact of the BEA award varied at our five case study banks. One bank reported that it would not have made an investment in a CDFI without the prospect of receiving an award from the Fund. In addition, a CDFI Fund official told us that some CDFIS marketed the prospect of receiving a BEA award as an incentive for banks to invest in Some Banks Do Not Maintain Data Needed to Measure Net Increases in Investment them. We found, however, that the prospect of an award did not influence other banks' investment activity. For example, two banks received awards totaling over $324,000 for increased investments they had made or agreed to make before the fiscal year 1996 awards were made. Banks have multiple incentives for investing in CDFIS and distressed areas. Therefore, it is difficult to isolate the impact of the BEA award from the effects of other incentives. According to our five case study banks, regulatory incentives, such as the need to comply with the Community Reinvestment Act (CRA), 5 often motivated the banks' investments in CDFIS and distressed communities, as did economic considerations. One bank said that such investments lay the groundwork for developing new markets, while other banks said that the investments help them maintain market share in areas targeted by the BEA program and compete with other banks in these areas. Two banks cited improved community relations as reasons for their investments. Some banks indicated that the BEA award provides a limited incentive, especially since it is relatively small and comes after a bank has already made at least an initial investment. According to Fund officials, a small portion of the 1996 awardees do not maintain the geographic data needed to determine whether any new investments in distressed areas are coming at the expense of other investments particularly agricultural, consumer, and small business loans-in such areas. Concerned about the validity of the net increases in investments in distressed areas reported by awardees, the Fund required the 1996 awardees that did not maintain such data to certify that, to the best of their knowledge, they had not decreased investments in distressed areas that were not linked to their BEA award. While most banks maintain the data needed to track their investments by census tract and can thus link their investments with distressed areas, a few do not do so for all types of investments.6 5Under CRA, federal banking agencies encourage banks to meet the credit needs of their communities. 6According to bank regulators, about 16 percent of the banks in the United States are geocoding (tracking by census tract) small business and small farm investments, and the remaining 84 percent are probably not geocoding such investments unless they are reporting loan activity under the Home Mortgage Disclosure Act. Compared with rural banks, nonrural banks are more likely to be geocoding their small business and farm loans, in part because it is easier for them to identify census tracts using specific addresses. Rural banks face difficulties associating census tracts with rural addresses. As a result, some banks are likely to continue to experience problems reporting on these types of activities. Fund Does Not Receive Information on Material Changes in Rewarded Investments Opportunities Exist for Improving the Fund's Strategic Plan The Fund does not require awardees to notify the Fund of material changes in their investments after awards have been made. Therefore, it does not know how long investments made under the program remain in place. We found, for example, that a CDFI in which one of our case study banks had invested was dissolved several months after the bank received a BEA award. The CDFI later repaid a portion of the bank's total investment. Because the Fund does not require banks to report their postaward activity, the Fund was not aware of this situation until we brought it to the attention of Fund officials. After hearing of the situation, a Fund official contacted the awardee and learned that the awardee plans to reinvest the funds in another CDFI. Even though this case has been resolved, Fund officials do not have a mechanism for determining whether investments made under the program remain in place. The CDFI statute does not require awardees to reinvest their awards in community development; however, most of the 1996 awardees have told the Fund, and we found through our case studies, that many of them are reinvesting at least a portion of their awards in community development. Reinvestment in community development is consistent with the goals of the BEA program. The CDFI Fund has more work to do before its strategic plan can fulfill the requirements of the Results Act. Though the plan covers the six basic elements required by the Results Act, these elements are generally not as specific, clear, and well linked as the act prescribes. However, the Fund is not unique in struggling to develop its strategic plan. We have found that federal agencies generally require sustained effort to develop the dynamic strategic planning processes envisioned by the Results Act. Difficulties that the Fund has encountered-in setting clear and specific strategic and performance goals, coordinating cross-cutting programs, and ensuring the capacity to gather and use performance and cost data-have faced many other federal agencies. Under the Results Act, an agency's strategic plan must contain (1) a comprehensive mission statement; (2) agencywide strategic goals and objectives for all major functions and operations; (3) strategies, skill, and technologies and the various resources needed to achieve the goals and objectives; (4) a relationship between the strategic goals and objectives and the annual performance goals; (5) an identification of key factors, external to the agency and beyond its control, that could significantly affect the achievement of the strategic goals and objectives; and (6) a description of how program evaluations were used to establish or revise strategic goals and objectives and a schedule for future program evaluations. OMB has provided agencies with additional guidance on developing their strategic plans.7 The Results Act anticipates that agencies may need several planning cycles to perfect their strategic plans, refining the plans from cycle to cycle. The Fund will, therefore, have opportunities for improving its strategic plan in each of the following areas: Mission In its strategic plan, the Fund states that its mission is "to promote economic revitalization and community development through investment in and assistance to community development financial institutions (CDFIS) and through encouraging insured depository institutions to increase lending, financial services and technical assistance within distressed communities and to invest in CDFIS. " Overall, the Fund's mission statement generally meets the requirements established in the Results Act by explicitly referring to the Fund's statutory objectives and indicating how these objectives are to be achieved through two core programs. Strategic Goals and Objectives Each agency's strategic plan is to set out strategic goals and objectives that delineate the agency's approach to carrying out its mission. The Fund's strategic plan contains 5 goals and 13 objectives, with each objective clearly related to a specific goal. However, OMB'S guidance suggests that strategic goals and objectives be stated in a manner that allows a future assessment to determine whether they were or are being achieved. Because none of the 5 goals (for example, to strengthen and expand the national network of CDFIS) and 13 objectives (for example, increase the number of organizations in training programs) in the strategic plan include baseline dates and values, deadlines, and targets, the Fund's goals and objectives do not meet this criterion. Strategies to Achieve Goals and Objectives The act also requires that an agency's strategic plan describe how the agency's goals and objectives are to be achieved. Results Act guidance suggests that this description address the skills and technologies, as well as the human, capital, information, and other resources, needed to achieve strategic goals and objectives. The Fund's plan shows mixed results in meeting these requirements. On the positive side, it clearly lists strategies 7See OMB Circular A-11. accomplishing goal objective-establishing linkages than the strategic plans of agencies that simply listed objectives and strategies in groups. On the other hand, the strategies themselves consist entirely of one-line statements. Because they generally lack detail, most are too vague or general to permit an assessment of whether their accomplishment will help achieve the plan's strategic goals and objectives. For example, it is unclear how the strategy of "emphasizing high quality standards in implementing the CDFI program" will specifically address the objective of "strengthening and expanding the national network of CDFIS. " Relationship Between Strategic and Annual Performance Goals The Fund's strategic plan lists 22 performance goals, which are clearly linked to specific strategic goals. However, the performance goals, like the Fund's strategic goals and objectives, generally lack sufficient specificity, as well as baseline and end values. These details would make the performance goals more tangible and measurable. For example, one performance goal is to "increase the number of applicants in the BEA program. " This goal would be more useful ifit specified the baseline number of applicants and projected an increase over a specified period of time. Also, some performance goals are stated more as strategies than as desired results. For example, it is not readily apparent how the performance goal of proposing legislative improvements to the BEA program will support the related strategic goal of encouraging investments in CDFIS by insured depository institutions. Key External Factors The Fund's strategic plan only partially meets the requirement of the Results Act and of OMB'S guidance that it describe key factors external to the Fund and beyond its control that could significantly affect the achievement of its objectives. While the plan briefly discusses external factors that could materially affect the Fund's performance, such as "national and regional economic trends, " these factors are not linked to specific strategic goals or objectives. Program Evaluations The Results Act defines program evaluations as assessments, through objective measurement and objective analysis, of the manner and extent to which federal programs achieve intended objectives. Although the Fund's plan does discuss various evaluation options, it does not discuss the role of program evaluations in either setting or measuring progress against all strategic goals. Also, the list of evaluation options does not describe the general scope or methodology for the evaluations, identify the key issues to be addressed, or indicate when the evaluations will occur. Other Matters Our review of the Fund's strategic plan also identified other areas that could be improved. For instance, OMB'S guidance on the Results Act directs that federal programs contributing to the same or similar outcomes should be coordinated to ensure that their goals are consistent and their efforts mutually reinforcing. The Fund's strategic plan does not explicitly address the relationship of the Fund's activities to similar activities in other agencies or indicate whether or how the Fund coordinated with other agencies in developing its strategic plan. Also, the capacity of the Fund to provide reliable information on the achievement of its strategic objectives at this point is somewhat unclear. Specifically, the Fund has not developed its strategic plan sufficiently to identify the types and the sources of data needed to evaluate its progress in achieving its strategic objectives. Moreover, according to a study prepared by KPMG Peat Marwick, the Fund has yet to set up a formal system, including procedures, to evaluate, continuously monitor, and improve the effectiveness of the management controls associated with the Fund's programs. As is consistent with the Results Act, the Fund is refining its plan by taking steps that, according to a key Fund official in charge of revising the plan, will address the shortcomings that we and the Department of the Treasury have identified. According to this official, the revised strategic plan, which the Fund expects to complete by August 1998, proposes to incorporate changes to the plan's strategic goals, including the elimination of the two that are organizational rather than strategic; a new format for presenting goals and objectives that links benchmarks and planned evaluations to each goal, along with key external factors that could affect the Fund's progress toward that goal; a budget structure that aligns the program's activities with sources and uses of funds to better track the resources required to implement the program's goals and objectives; a performance goal that measures the ability of the Fund to leverage its resources with those of the private sector; and an identification and description of crosscutting organizations and programs that duplicate or compliment the CDFI Fund's programs. In closing, Madam Chair, our preliminary review has identified several opportunities for the Fund to improve the effectiveness of the CDFI and BEA programs and of its strategic planning effort. In our view, these opportunities exist, in part, because the Fund is new and is experiencing the typical growing pains associated with setting up an agency-particularly one that has the relatively complex and long-term mission of promoting economic revitalization and community development in low-income communities. In addition, staffing limitations have delayed the development of monitoring and evaluations systems. Recently, however, the Fund has hired several senior staff-including a director; two deputy directors, one of whom also serves as the chief financial officer; an awards manager; a financial manager; and program managers- -and is reportedly close to hiring an evaluations director. While it is too early to assess the impact of filling these positions, the new managers have initiated actions to improve the programs and the strategic plan. In our final report, we expect to make recommendations to further improve the operations of the CDFI Fund and its programs. Madam Chair, this concludes our testimony. We would be pleased to respond to any questions that you or Members of the Committee may have at this time.